{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Project_Composer_Mashup1_LSTM.ipynb","provenance":[{"file_id":"19TQqekOlnOSW36VCL8CPVEQKBBukmaEQ","timestamp":1574044218627}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"btYHx_uBWmcj","colab_type":"text"},"source":["## SCS_3546_006 Term Project - Yang Sui\n","# **Music Generation using RNN**\n","---\n","Inspired by [this Toward Data Science article by Sigurður Skúli](https://towardsdatascience.com/how-to-generate-music-using-a-lstm-neural-network-in-keras-68786834d4c5).\n","\n","Code borrowed and modified from [this Github project](https://github.com/unmonoqueteclea/DeepLearning-Notebooks/tree/master/LSTM-Music-Generation).\n","\n","Improvements from the referenced code are discussed throughout this notebook."]},{"cell_type":"markdown","metadata":{"id":"uJHo_GbVd-cd","colab_type":"text"},"source":["# Music generation with LSTM in Keras\n","In this notebook, I am **generate some piano compositions** using a Long Short-Term Memory (LSTM) network. I'm using some piano compositions from Beethoven and Mozart to form the training data for the network. I feed the network with a long sequence of notes parsed from **MIDI files** of Beethoven and Mozart piano pieces. After training, the network will be able to generate new MIDI files."]},{"cell_type":"markdown","metadata":{"id":"DDOBVWULXfpz","colab_type":"text"},"source":["## LSTM networks\n","Long Short-Term Memory networks are one type of **Recurrent Neural Network (RNN)**. \n","They are networks whose output depends on the previous ones. This loop behaviour makes them the perfect option to work with sequences and lists. LSTM in particular is designed to capture long-term dependencies, i.e. remember information for long periods.\n","\n","## Music learning and generation\n","Training dataset is parsed from MIDI files of piano music. MIDI file contain information about music, rather than the audio signal of a recording of the music being played. It is easy to pull information from a MIDI file. For this model, I read the MIDI files to find out what note on the piano is being played. Those notes are encoded into the training data array.\n","\n","After training, the network is asked to generate new sequences of notes. That sequence is easily encoded into a MIDI file which can then be played by media player software (e.g. Windows Media Player).\n"]},{"cell_type":"markdown","metadata":{"id":"8Rn0ZBBI1OT8","colab_type":"text"},"source":["## Google drive configuration for Colab\n","Mount my **Google Drive** as a drive to store files generated from the model."]},{"cell_type":"code","metadata":{"id":"NP-dwUiX1OEb","colab_type":"code","outputId":"6ca9b6e4-ab88-4338-88e0-b37a49c2b1b3","executionInfo":{"status":"ok","timestamp":1575332486148,"user_tz":300,"elapsed":22999,"user":{"displayName":"Yang Sui","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDtMu3_EjdDQQ_kQLRCgsfL05IP1IsHFdWHDL3UHA=s64","userId":"08027483007346071649"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","# Mount my google drive as a drive on Colab\n","drive.mount('/content/drive')\n","\n","#use variable wd to store the working directory path as the \"Input\" folder provided with this exercise\n","wd = \"/content/drive/My Drive/UofT Deep Learning Course/Project/Temp\""],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"q4cCdRCwePQW","colab_type":"text"},"source":["## Packages and data\n","Use [**music21 package**](http://web.mit.edu/music21/) to process MIDI files to get only the information needed and discard the rest.\n","\n","Music21 creates its own representation of a MIDI file, with different **Note** and **Chord** objects representing all the music inside a MIDI file. It's a representation easier to read than the MIDI one, so it will help our network to *understand* music and be able to create new compositions."]},{"cell_type":"code","metadata":{"id":"Wo4ARjCTdzA0","colab_type":"code","outputId":"29d7139c-4e43-4e20-c58a-55f37acdc28f","executionInfo":{"status":"ok","timestamp":1574109184945,"user_tz":300,"elapsed":3272,"user":{"displayName":"Yang Sui","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDtMu3_EjdDQQ_kQLRCgsfL05IP1IsHFdWHDL3UHA=s64","userId":"08027483007346071649"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["!pip install music21;"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: music21 in /usr/local/lib/python3.6/dist-packages (5.5.0)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"i0JdZncylpx-","colab_type":"text"},"source":["### Original MIDI files\n"," **MIDI files** used in for training come from [piano-midi.de](http://www.piano-midi.de/midis/format0/).\n"," \n","This training set contain 29 MIDI files from Beethoven and 21 files from Mozart."]},{"cell_type":"code","metadata":{"id":"UAGpdsQtiLrk","colab_type":"code","outputId":"8d2a43dc-fc05-45f2-ac15-09b11875dea1","executionInfo":{"status":"ok","timestamp":1574289987660,"user_tz":300,"elapsed":819,"user":{"displayName":"Yang Sui","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDtMu3_EjdDQQ_kQLRCgsfL05IP1IsHFdWHDL3UHA=s64","userId":"08027483007346071649"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# list the files on the Colab drive\n","!ls"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Beethoven  drive  midi_files_BeethovenMozart.zip  Mozart  notes  sample_data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YZsJNxERie5g","colab_type":"code","colab":{}},"source":["# Clean up the Colab drive in case of mistakes.\n","#!rm -rf midi_files/"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IlcAs_63gupm","colab_type":"code","outputId":"1042aefd-f4b3-445b-d1bd-9d8befe7bc8f","executionInfo":{"status":"ok","timestamp":1575044783908,"user_tz":300,"elapsed":13954,"user":{"displayName":"Yang Sui","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDtMu3_EjdDQQ_kQLRCgsfL05IP1IsHFdWHDL3UHA=s64","userId":"08027483007346071649"}},"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":91}},"source":["from google.colab import files\n","uploaded = files.upload()\n","\n","for fn in uploaded.keys():\n","  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n","      name=fn, length=len(uploaded[fn])))"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-e96ee7e7-8c66-4249-b23a-603841c7f821\" name=\"files[]\" multiple disabled />\n","     <output id=\"result-e96ee7e7-8c66-4249-b23a-603841c7f821\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving midi_files_BeethovenMozart.zip to midi_files_BeethovenMozart.zip\n","User uploaded file \"midi_files_BeethovenMozart.zip\" with length 507600 bytes\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"i6rzo2WipNDv","colab_type":"code","outputId":"aea269dd-ba21-4c5c-9d09-caf6dc976f25","executionInfo":{"status":"ok","timestamp":1575044789290,"user_tz":300,"elapsed":3909,"user":{"displayName":"Yang Sui","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDtMu3_EjdDQQ_kQLRCgsfL05IP1IsHFdWHDL3UHA=s64","userId":"08027483007346071649"}},"colab":{"base_uri":"https://localhost:8080/","height":918}},"source":["!unzip midi_files_BeethovenMozart.zip;"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Archive:  midi_files_BeethovenMozart.zip\n","   creating: Beethoven/\n","  inflating: Beethoven/appass_1.mid  \n","  inflating: Beethoven/appass_2.mid  \n","  inflating: Beethoven/appass_3.mid  \n","  inflating: Beethoven/beethoven_hammerklavier_1.mid  \n","  inflating: Beethoven/beethoven_hammerklavier_2.mid  \n","  inflating: Beethoven/beethoven_hammerklavier_3.mid  \n","  inflating: Beethoven/beethoven_hammerklavier_4.mid  \n","  inflating: Beethoven/beethoven_les_adieux_1.mid  \n","  inflating: Beethoven/beethoven_les_adieux_2.mid  \n","  inflating: Beethoven/beethoven_les_adieux_3.mid  \n","  inflating: Beethoven/beethoven_opus10_1.mid  \n","  inflating: Beethoven/beethoven_opus10_2.mid  \n","  inflating: Beethoven/beethoven_opus10_3.mid  \n","  inflating: Beethoven/beethoven_opus22_1.mid  \n","  inflating: Beethoven/beethoven_opus22_2.mid  \n","  inflating: Beethoven/beethoven_opus22_3.mid  \n","  inflating: Beethoven/beethoven_opus22_4.mid  \n","  inflating: Beethoven/beethoven_opus90_1.mid  \n","  inflating: Beethoven/beethoven_opus90_2.mid  \n","  inflating: Beethoven/elise.mid     \n","  inflating: Beethoven/mond_1.mid    \n","  inflating: Beethoven/mond_2.mid    \n","  inflating: Beethoven/mond_3.mid    \n","  inflating: Beethoven/pathetique_1.mid  \n","  inflating: Beethoven/pathetique_2.mid  \n","  inflating: Beethoven/pathetique_3.mid  \n","  inflating: Beethoven/waldstein_1.mid  \n","  inflating: Beethoven/waldstein_2.mid  \n","  inflating: Beethoven/waldstein_3.mid  \n","   creating: Mozart/\n","  inflating: Mozart/mz_311_1.mid     \n","  inflating: Mozart/mz_311_2.mid     \n","  inflating: Mozart/mz_311_3.mid     \n","  inflating: Mozart/mz_330_1.mid     \n","  inflating: Mozart/mz_330_2.mid     \n","  inflating: Mozart/mz_330_3.mid     \n","  inflating: Mozart/mz_331_1.mid     \n","  inflating: Mozart/mz_331_2.mid     \n","  inflating: Mozart/mz_331_3.mid     \n","  inflating: Mozart/mz_332_1.mid     \n","  inflating: Mozart/mz_332_2.mid     \n","  inflating: Mozart/mz_332_3.mid     \n","  inflating: Mozart/mz_333_1.mid     \n","  inflating: Mozart/mz_333_2.mid     \n","  inflating: Mozart/mz_333_3.mid     \n","  inflating: Mozart/mz_545_1.mid     \n","  inflating: Mozart/mz_545_2.mid     \n","  inflating: Mozart/mz_545_3.mid     \n","  inflating: Mozart/mz_570_1.mid     \n","  inflating: Mozart/mz_570_2.mid     \n","  inflating: Mozart/mz_570_3.mid     \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VfXedNx5paKS","colab_type":"text"},"source":["## Processing data\n","\n","Let's process the files, and load them into **music21**"]},{"cell_type":"code","metadata":{"id":"bNID-MfGglBp","colab_type":"code","outputId":"028253ae-5bc0-4996-bf7c-ab977aa9935d","executionInfo":{"status":"ok","timestamp":1575332495319,"user_tz":300,"elapsed":3112,"user":{"displayName":"Yang Sui","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDtMu3_EjdDQQ_kQLRCgsfL05IP1IsHFdWHDL3UHA=s64","userId":"08027483007346071649"}},"colab":{"base_uri":"https://localhost:8080/","height":80}},"source":["# Importing dependencies\n","import glob\n","import pickle\n","import numpy\n","from music21 import converter, instrument, note, chord, stream\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, LSTM, Activation\n","from keras.utils import np_utils\n","from keras.callbacks import ModelCheckpoint"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"UvQHUqw0t8MM","colab_type":"text"},"source":["**music21** represents music with two elements:\n","- **Notes**\n","- **Chords**\n","\n","Each element also has a time offset indicating when the note or chord is played."]},{"cell_type":"code","metadata":{"id":"yxLB-WnEuBlR","colab_type":"code","outputId":"77656e06-fef7-4c24-8b4c-25894e682e70","executionInfo":{"status":"ok","timestamp":1575044819083,"user_tz":300,"elapsed":23456,"user":{"displayName":"Yang Sui","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDtMu3_EjdDQQ_kQLRCgsfL05IP1IsHFdWHDL3UHA=s64","userId":"08027483007346071649"}},"colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["# check that music21 can parse an example MIDI file\n","file = \"Beethoven/appass_1.mid\"\n","midi = converter.parse(file)\n","notes_to_parse = midi.flat.notes\n","for element in notes_to_parse[:10]:\n","  print(element, element.offset)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["<music21.note.Note C> 4.5\n","<music21.note.Note C> 4.5\n","<music21.note.Note G#> 5.75\n","<music21.note.Note G#> 5.75\n","<music21.note.Note F> 6.0\n","<music21.note.Note F> 6.0\n","<music21.note.Note G#> 10.5\n","<music21.note.Note G#> 10.5\n","<music21.note.Note C> 11.75\n","<music21.note.Note C> 11.75\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_vrSUm7Jgok_","colab_type":"text"},"source":["- A **note** is stored in the list as a string representing the pitch (the note name) and the octave.\n","\n","- A **chord** (set of notes played at the same time) will be stored as a string of numbers separated by dots. Each number represents the pitch of a note within the chord.\n","\n","**This approach does not consider time offsets of each element**. I.e. the note offset is not captured. This only encodes the order of notes/chords in a piece of music. The duration of each note/chord is also not captured. This sequence of notes/chords is stored in the 'notes' array, which serves as the training data for this model."]},{"cell_type":"code","metadata":{"id":"UgaL_DwL9V0P","colab_type":"code","outputId":"5655e9b3-e540-4ef5-9aa1-b2d52cc2368d","executionInfo":{"status":"ok","timestamp":1575045331842,"user_tz":300,"elapsed":491346,"user":{"displayName":"Yang Sui","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDtMu3_EjdDQQ_kQLRCgsfL05IP1IsHFdWHDL3UHA=s64","userId":"08027483007346071649"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["notes = []\n","# loop through all files for first composer\n","for i,file in enumerate(glob.glob(\"Beethoven/*.mid\")):\n","  midi = converter.parse(file)\n","  print('\\r', 'Parsing file ', i, \" \",file, end='')\n","  notes_to_parse = None\n","  try: # file has instrument parts\n","    s2 = instrument.partitionByInstrument(midi)\n","    notes_to_parse = s2.parts[0].recurse() \n","  except: # file has notes in a flat structure\n","    notes_to_parse = midi.flat.notes\n","  for element in notes_to_parse:\n","    if isinstance(element, note.Note):\n","      notes.append(str(element.pitch))\n","    elif isinstance(element, chord.Chord):\n","      notes.append('.'.join(str(n) for n in element.normalOrder))\n","\n","# loop through all files for second composer\n","for i,file in enumerate(glob.glob(\"Mozart/*.mid\")):\n","  midi = converter.parse(file)\n","  print('\\r', 'Parsing file ', i, \" \",file, end='')\n","  notes_to_parse = None\n","  try: # file has instrument parts\n","    s2 = instrument.partitionByInstrument(midi)\n","    notes_to_parse = s2.parts[0].recurse() \n","  except: # file has notes in a flat structure\n","    notes_to_parse = midi.flat.notes\n","  for element in notes_to_parse:\n","    if isinstance(element, note.Note):\n","      notes.append(str(element.pitch))\n","    elif isinstance(element, chord.Chord):\n","      notes.append('.'.join(str(n) for n in element.normalOrder))\n","\n","with open('notes', 'wb') as filepath:\n","  pickle.dump(notes, filepath)\n","\n","# save notes array for reloading later if I lose Colab connection\n","with open(wd + '/mashup1_notes', 'wb') as filepath2:\n","  pickle.dump(notes, filepath2)"],"execution_count":0,"outputs":[{"output_type":"stream","text":[" Parsing file  20   Mozart/mz_332_3.mid"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pxqbbu6pAgTh","colab_type":"code","colab":{}},"source":["# or re-load previously saved 'notes' variable values instead of rebuilding from the zip file again.\n","with open(wd + '/mashup1_notes', 'rb') as filepath:\n","  notes = pickle.load(filepath)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gHrD-1RijteB","colab_type":"text"},"source":["Obtain the number of different notes in the dataset. This will be the **number of possible output classes**  of the model."]},{"cell_type":"code","metadata":{"id":"7Lho6SJW8HP3","colab_type":"code","outputId":"db231e36-9d33-43c4-9f5e-4a197db9787c","executionInfo":{"status":"ok","timestamp":1575344800049,"user_tz":300,"elapsed":598,"user":{"displayName":"Yang Sui","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDtMu3_EjdDQQ_kQLRCgsfL05IP1IsHFdWHDL3UHA=s64","userId":"08027483007346071649"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Count different possible outputs\n","n_vocab = (len(set(notes)))\n","n_vocab"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["285"]},"metadata":{"tags":[]},"execution_count":49}]},{"cell_type":"markdown","metadata":{"id":"U5lUC-oTj41-","colab_type":"text"},"source":["Now some **data processing** is required:\n","\n","- map each pitch or chord to an integer\n","- create a dictionary pairing input sequences to their corresponding output note (output note being the note/chord immediatedly after the last note/chord in the input sequence).\n","\n","Surely, different **sequence_length** will lead to different results. The original tutorial I borrowed this model from used a sequence length of 100. In this model, I'm trying a sequence_length of 50.\n","\n","The network will make its prediction of the next note/chord, based on the previous *sequence_length* notes/chords. \n","\n","![alt text](https://raw.githubusercontent.com/yangsui05/Music-generation-LSTM/master/inputoutputsequences_corrected.png)"]},{"cell_type":"code","metadata":{"id":"K7ewLUx0-vJw","colab_type":"code","colab":{}},"source":["sequence_length = 50\n","# get all pitch names\n","pitchnames = sorted(set(item for item in notes))\n","# create a dictionary to map pitches to integers\n","note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n","network_input = []\n","network_output = []\n","# create input sequences and the corresponding outputs\n","for i in range(0, len(notes) - sequence_length, 1):\n","  sequence_in = notes[i:i + sequence_length] # Size sequence_length\n","  sequence_out = notes[i + sequence_length]  # Size 1\n","  # Map pitches of sequence_in to integers\n","  network_input.append([note_to_int[char] for char in sequence_in])\n","  # Map integer of sequence_out to an integer\n","  network_output.append(note_to_int[sequence_out])\n","n_patterns = len(network_input)\n","# reshape the input into a format compatible with LSTM layers\n","network_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1))\n","# normalize input\n","network_input = network_input / float(n_vocab)\n","network_output = np_utils.to_categorical(network_output)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cvkOsHQN1P51","colab_type":"text"},"source":["Checking the network_input size"]},{"cell_type":"code","metadata":{"id":"bppzcWdM1Sk-","colab_type":"code","outputId":"3ca33bcb-0f19-4954-cfd3-eae13f7c998d","executionInfo":{"status":"ok","timestamp":1575126897716,"user_tz":300,"elapsed":1153,"user":{"displayName":"Yang Sui","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDtMu3_EjdDQQ_kQLRCgsfL05IP1IsHFdWHDL3UHA=s64","userId":"08027483007346071649"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["network_input.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(146004, 50, 1)"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"AfzYkhxEuY8D","colab_type":"text"},"source":["## Creating model\n","\n","Create a network with 9 layers (3 of them **LSTM layers**).\n","\n","For regularization, add 3 **Dropout** layers in betweeen."]},{"cell_type":"code","metadata":{"id":"IH2fW6Ot-vN-","colab_type":"code","colab":{}},"source":["def create_network(network_input, n_vocab):\n","    \"\"\" create the structure of the neural network \"\"\"\n","    model = Sequential()\n","    model.add(LSTM(\n","        512,\n","        input_shape=(network_input.shape[1], network_input.shape[2]),\n","        return_sequences=True\n","    ))\n","    model.add(Dropout(0.3))\n","    model.add(LSTM(512, return_sequences=True))\n","    model.add(Dropout(0.3))\n","    model.add(LSTM(512))\n","    model.add(Dense(256))\n","    model.add(Dropout(0.3))\n","    model.add(Dense(n_vocab))\n","    model.add(Activation('softmax'))\n","    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yO5HenQR1zwr","colab_type":"code","outputId":"84fc587e-9b15-4c60-88b4-6a56ace46380","executionInfo":{"status":"ok","timestamp":1575340182076,"user_tz":300,"elapsed":3068,"user":{"displayName":"Yang Sui","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDtMu3_EjdDQQ_kQLRCgsfL05IP1IsHFdWHDL3UHA=s64","userId":"08027483007346071649"}},"colab":{"base_uri":"https://localhost:8080/","height":459}},"source":["model = create_network(network_input,n_vocab)\n","model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","lstm_7 (LSTM)                (None, 50, 512)           1052672   \n","_________________________________________________________________\n","dropout_7 (Dropout)          (None, 50, 512)           0         \n","_________________________________________________________________\n","lstm_8 (LSTM)                (None, 50, 512)           2099200   \n","_________________________________________________________________\n","dropout_8 (Dropout)          (None, 50, 512)           0         \n","_________________________________________________________________\n","lstm_9 (LSTM)                (None, 512)               2099200   \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 256)               131328    \n","_________________________________________________________________\n","dropout_9 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 285)               73245     \n","_________________________________________________________________\n","activation_3 (Activation)    (None, 285)               0         \n","=================================================================\n","Total params: 5,455,645\n","Trainable params: 5,455,645\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NhWEyBhz3WSn","colab_type":"text"},"source":["(Optional) load in previously trained weights. For restarts in case Colab dropped connection or to continue training from a specific epoch."]},{"cell_type":"code","metadata":{"id":"-3D_madC_mFA","colab_type":"code","colab":{}},"source":["# In case we want to use previously trained weights\n","weights = \"\"\n","if(len(weights)>0): model.load_weights(weights)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EvkVdhBW-voq","colab_type":"code","colab":{}},"source":["# In case we want to use previously trained weights\n","weights = wd + \"/mashup1_best.h5\"\n","if(len(weights)>0): model.load_weights(weights)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AC2RDfrvmq6b","colab_type":"text"},"source":["# Train the model\n","Use **ModelCheckpoint** to save the best weights during training. Saved weights can be reloaded later to continue training if Colab connection is lost."]},{"cell_type":"code","metadata":{"id":"tpv-8gT3-vrM","colab_type":"code","outputId":"84ade2dc-cec1-41b6-9502-c593d9a02849","executionInfo":{"status":"ok","timestamp":1575348368310,"user_tz":300,"elapsed":3554267,"user":{"displayName":"Yang Sui","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDtMu3_EjdDQQ_kQLRCgsfL05IP1IsHFdWHDL3UHA=s64","userId":"08027483007346071649"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["#filepath = wd + \"/mashup1_best.h5\"\n","filepath = wd + \"/mashup1_best.h5\"\n","\n","checkpoint = ModelCheckpoint(filepath, monitor='loss',verbose=0,\n","                             save_best_only=True,mode='min')\n","\n","callbacks_list = [checkpoint]\n","model.fit(network_input, network_output, epochs=5, batch_size=64, \n","          callbacks=callbacks_list)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/5\n","146004/146004 [==============================] - 695s 5ms/step - loss: 3.4867\n","Epoch 2/5\n","146004/146004 [==============================] - 708s 5ms/step - loss: 3.3768\n","Epoch 3/5\n","146004/146004 [==============================] - 710s 5ms/step - loss: 3.2650\n","Epoch 4/5\n","146004/146004 [==============================] - 708s 5ms/step - loss: 3.1646\n","Epoch 5/5\n","146004/146004 [==============================] - 728s 5ms/step - loss: 3.0702\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f9b1a9d1550>"]},"metadata":{"tags":[]},"execution_count":51}]},{"cell_type":"markdown","metadata":{"id":"qUIMPOdbwJhT","colab_type":"text"},"source":["## Music generation\n","\n","After the model is trained, it can be used to generate music (sequence of notes/chords to turn into a MIDI file).\n","\n","![Music Generation](https://raw.githubusercontent.com/yangsui05/Music-generation-LSTM/master/Generative%20workflow_corrected.png)"]},{"cell_type":"code","metadata":{"id":"C5FHJ6sq8HX7","colab_type":"code","colab":{}},"source":["# In case I want to use other previously trained weights\n","weights = wd + \"/mashup1_best.h5\"\n","if(len(weights)>0): model.load_weights(weights)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qAdOj4d0ExMq","colab_type":"code","colab":{}},"source":["# Generate network input again\n","network_input = []\n","output = []\n","for i in range(0, len(notes) - sequence_length, 1):\n","  sequence_in = notes[i:i + sequence_length]\n","  sequence_out = notes[i + sequence_length]\n","  network_input.append([note_to_int[char] for char in sequence_in])\n","  output.append(note_to_int[sequence_out])\n","n_patterns = len(network_input)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HjlwzJQv6OKc","colab_type":"text"},"source":["The workflow now is:\n","\n","\n","1.   Pick a **seed sequence** randomly from the list of inputs (*pattern* variable)\n","2.   Pass it as input to the model to generate a new element (note or chord)\n","3.   Add the new element to the final song (prediction_output variable) and the *pattern* list\n","4.   Remove the first item from *pattern*.\n","5.   Go to step 2, repeat for the number of elements desired.\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"F2fkoEiw8HaI","colab_type":"code","outputId":"9088600e-25af-4106-d034-673bc70c0912","executionInfo":{"status":"ok","timestamp":1575348650901,"user_tz":300,"elapsed":6872,"user":{"displayName":"Yang Sui","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDtMu3_EjdDQQ_kQLRCgsfL05IP1IsHFdWHDL3UHA=s64","userId":"08027483007346071649"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["\"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"\n","# number of notes to generate\n","numNotes = 50\n","\n","# pick a random sequence from the input as a starting point for the prediction\n","start = numpy.random.randint(0, len(network_input)-1)\n","int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n","pattern = network_input[start]\n","prediction_output = []\n","# generate notes\n","for i,note_index in enumerate(range(numNotes)):\n","  prediction_input = numpy.reshape(pattern, (1, len(pattern), 1))\n","  prediction_input = prediction_input / float(n_vocab)\n","  prediction = model.predict(prediction_input, verbose=0)\n","  index = numpy.argmax(prediction)\n","  result = int_to_note[index]\n","  print('\\r', 'Predicted ', i, \" \",result, end='')\n","  prediction_output.append(result)\n","  pattern.append(index)\n","  pattern = pattern[1:len(pattern)]"],"execution_count":0,"outputs":[{"output_type":"stream","text":[" Predicted  49   E4"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RpOqIhgzEAeX","colab_type":"text"},"source":["The last step is creating a MIDI file from the predictions.\n","\n","**music21** will once again be used for this task. Create a **Stream** and add to it the predicted notes and chords (elements of the predicted_output array.\n","\n","Add an offset of 0.5 between elements. This is required because the sequence of notes generated by the model does not have timing information. This step manually puts the generated notes on a timeline with equal duration for each note. This simulates a song that only contains quarter notes. Obviously, this isn't real music as real music has variation in note duration. But it's a compromise for now. Updating the model to account for note duration is reserved for future work."]},{"cell_type":"code","metadata":{"id":"pub0aRJU8Hcu","colab_type":"code","outputId":"c0c37379-8e58-4dc7-b6fe-006877280e60","executionInfo":{"status":"ok","timestamp":1575348654324,"user_tz":300,"elapsed":848,"user":{"displayName":"Yang Sui","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDtMu3_EjdDQQ_kQLRCgsfL05IP1IsHFdWHDL3UHA=s64","userId":"08027483007346071649"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["offset = 0\n","output_notes = []\n","# create note and chord objects based on the values generated by the model\n","for pattern in prediction_output:\n","    # pattern is a chord\n","    if ('.' in pattern) or pattern.isdigit():\n","        notes_in_chord = pattern.split('.')\n","        notes = []\n","        for current_note in notes_in_chord:\n","            new_note = note.Note(int(current_note))\n","            new_note.storedInstrument = instrument.Piano()\n","            notes.append(new_note)\n","        new_chord = chord.Chord(notes)\n","        new_chord.offset = offset\n","        output_notes.append(new_chord)\n","    # pattern is a note\n","    else:\n","        new_note = note.Note(pattern)\n","        new_note.offset = offset\n","        new_note.storedInstrument = instrument.Piano()\n","        output_notes.append(new_note)\n","\n","    # increase offset each iteration so that notes do not stack\n","    offset += 0.5\n","\n","midi_stream = stream.Stream(output_notes)\n","midi_stream.write('midi', fp=wd + '/mashup1_output.mid')"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/My Drive/UofT Deep Learning Course/Project/Temp/mashup1_output.mid'"]},"metadata":{"tags":[]},"execution_count":61}]},{"cell_type":"code","metadata":{"id":"gfc70nka1hVw","colab_type":"code","colab":{}},"source":["from google.colab import files\n","files.download(wd + '/mashup1_output.mid')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vjEcqFw0KVdw","colab_type":"text"},"source":["# Sample output\n","Follow the following link to an mp3 of sample output from this model.\n","[Sample Output](https://github.com/yangsui05/Music-generation-LSTM/blob/master/mashup1_seqSize50_epochs10_20_26_46_72_90.mp3)\n","\n","This sample mp3 demonstrates the evolution of the training of this model. It consists of 10 seconds of the model output at 10 epochs, 20 epochs, 26 epochs, 46 epochs, 72 epochs, and 90 epochs, with short silences in between."]},{"cell_type":"markdown","metadata":{"id":"rfSPLkqjO11-","colab_type":"text"},"source":["# Next steps\n","There are many things I would like to continue to explore and improve:\n","- Account for note/chord duration so that output sounds more like intentionally composed music.\n","- Try mashing up musical styles that are very different. E.g. video game music with jazz, rag time piano with classical etc.\n","- Try mashing up many more composers and musical styles.\n","- Explore different sequence lengths and other hyperparameter values.\n","- Explore how to add an element of creativity. Perhaps supplement or augment the model's musical vocabulary."]}]}